{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar = tf.keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 15, 15, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation=LeakyReLU(), input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=LeakyReLU()))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=LeakyReLU()))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation=LeakyReLU()))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=SGD(0.0001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2519 - accuracy: 0.9326 - val_loss: 1.3167 - val_accuracy: 0.6357\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2410 - accuracy: 0.9374 - val_loss: 1.3180 - val_accuracy: 0.6327\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2277 - accuracy: 0.9430 - val_loss: 1.3553 - val_accuracy: 0.6330\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.2147 - accuracy: 0.9471 - val_loss: 1.3685 - val_accuracy: 0.6312\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.2042 - accuracy: 0.9522 - val_loss: 1.3706 - val_accuracy: 0.6284\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.1727 - accuracy: 0.9632 - val_loss: 1.4363 - val_accuracy: 0.6267\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.1616 - accuracy: 0.9677 - val_loss: 1.4698 - val_accuracy: 0.6317\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.1534 - accuracy: 0.9688 - val_loss: 1.4854 - val_accuracy: 0.6249\n"
     ]
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/fit_LeakyReLU_SGD/\n",
    "\n",
    "log_dir = \"logs/fit_LeakyReLU_SGD/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_split=0.2, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 1.1019 - accuracy: 0.6330\n",
      "0.6330000162124634\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,  y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(0.0001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.1435 - accuracy: 0.9733 - val_loss: 1.5183 - val_accuracy: 0.6269\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.1350 - accuracy: 0.9746 - val_loss: 1.5402 - val_accuracy: 0.6247\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.1278 - accuracy: 0.9771 - val_loss: 1.5486 - val_accuracy: 0.6247\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.1158 - accuracy: 0.9816 - val_loss: 1.5757 - val_accuracy: 0.6233\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.1115 - accuracy: 0.9828 - val_loss: 1.5845 - val_accuracy: 0.6245\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.1034 - accuracy: 0.9856 - val_loss: 1.6179 - val_accuracy: 0.6261\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.0978 - accuracy: 0.9858 - val_loss: 1.6566 - val_accuracy: 0.6161\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.0931 - accuracy: 0.9874 - val_loss: 1.6591 - val_accuracy: 0.6253\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.0843 - accuracy: 0.9902 - val_loss: 1.6720 - val_accuracy: 0.6255\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 0.0789 - accuracy: 0.9914 - val_loss: 1.6924 - val_accuracy: 0.6242\n"
     ]
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/fit_LeakyReLU_Adam/\n",
    "\n",
    "log_dir = \"logs/fit_LeakyReLU_Adam/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_split=0.2, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 1.7078 - accuracy: 0.6160\n",
      "0.6160000562667847\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,  y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-2882557728203b1f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-2882557728203b1f\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#/gradient_tape\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
